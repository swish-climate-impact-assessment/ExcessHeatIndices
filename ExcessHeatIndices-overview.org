#+TITLE:Excess Heat Indices 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----
* TODO-list
** TODO fix lags using zoo package, rollmean
** TODO add apparent temperature
* Introduction
#+name:README.md
#+begin_src markdown :tangle README.md :exports none :eval no
Excess Heat Indices	
-------------------

During 2011 I worked for Geoff Morgan (Geoff.Morgan@ncahs.health.nsw.gov.au) on a consultancy with NSW health to look at heatwaves, mortality and admissions. We use the percentiles of daily max temperature and apparent temperature in a similar way to the paper by Behnoosh Khalaj and Keith Dear. In additional sensitivity analyses we also developed material related to a newly proposed heatwave metric called the Excess Heat Factor by John Nairn at the BoM.

The reports/EHIs_transformations_doc.Rnw file is an Sweave document which contains the complete text and R codes that you can execute and produce the PDF (also found in the reports directory).  The interested reader is encouraged to run the R codes to do the calculations and generate the graphs that get compiled into that pdf file.  These R codes are also held separately in the src directory and can be evaluated in the correct sequence using the go.r script if you prefer.  Please don't hesitate to send me queries or comments on the algorithms or other aspects of this work.

Some Background
---------------

We were asked by our NSW health collaborators to investigate some heatwave indices developed by the BoM. NSW BoM like the look of three indices invented at the SA BoM office (by John Nairn) - they want to construct a national definition. Apparently BoM central HQ like John's definition the most (not published in a journal yet, the best ref is http://www.cawcr.gov.au/events/modelling_workshops/workshop_2009/papers/NAIRN.pdf). 

John has worked with PriceWaterhouseCoopers to apply the heatwave in a recent report http://www.pwc.com.au/industry/government/assets/extreme-heat-events-nov11.pdf

Ivan Hanigan

#+end_src

* Codes
** ExcessHeatIndices-package.Rd
#+name:ExcessHeatIndices-package.Rd
#+begin_src markdown  :tangle man/ExcessHeatIndices-package.Rd :exports none :eval no
  \name{ExcessHeatIndices-package}
  \alias{ExcessHeatIndices-package}
  \alias{ExcessHeatIndices}
  \docType{package}
  \title{
  Excess Heat Indices 
  }
  \description{
  Excess Heat Indices for Human Health research
  }
  \details{
  \tabular{ll}{
  Package: \tab ExcessHeatIndices\cr
  Type: \tab Package\cr
  Version: \tab 1.1.1\cr
  Date: \tab 2017-09-19\cr
  License: \tab GPL2\cr
  }

  }
  \author{
  ivanhanigan, James Goldie, Joseph Guillaume
  Maintainer:  ivan.hanigan@gmail.com 
  }
  \references{
  Wilson, L. A., Morgan, G., Hanigan, I. C., Johnston, F., Abu-Rayya, H., Broome, R., … Jalaludin, B. (2013). The impact of heat on mortality and morbidity in the Greater Metropolitan Sydney Region: a case crossover analysis. Environmental Health : A Global Access Science Source, 12(1), 98. http://doi.org/10.1186/1476-069X-12-98
  }

  \keyword{ Heatwaves }
      
#+end_src

** tests
#+name:tests
#+begin_src R :session *R* :tangle tests.r :exports none :eval no
  require(testthat)
  
  test_dir('tests', reporter = 'Summary')
  
#+end_src

** EHF
*** test
#+name:test-EHF
#+begin_src R :session *R* :tangle tests/test-EHF.r :exports none :eval no
  # first test
  dir()
  source('../R/EHF.r')
  require(swishdbtools)
  require(plyr)
  # access to ewedb is password restricted
  ch <- connect2postgres2('ewedb')
  slacode <- sql_subset(ch,"abs_sla.aussla01", subset = "sla_name = 'Scullin'",
             select = c("sla_code, sla_name"), eval=T)
  sql <- sql_subset(ch,"weather_sla.weather_sla",
                   subset=paste("sla_code = '",slacode$sla_code,"'",sep=""), eval = F)
  cat(sql)
  # this might take some minutes
  df <- dbGetQuery(ch, sql)
  head(df)
  tail(df)
  with(df, plot(date, maxave))
  str(df)
  df2 <- EHF(df, 'maxave', "date", min(df$date), max(df$date))
  names(df2)
  hist(subset(df2, EHF >= 1)[,'EHF'])
  threshold <- quantile(subset(df2, EHF >= 1)[,'EHF'], probs=0.9)
  
  with(df, plot(date, maxave, type = 'l'))
  with(subset(df2, EHF > threshold), points(date, maxave, col = 'red', pch = 16))
  
#+end_src

*** R/EHF
#+name:EHF
#+begin_src R :session *R* :tangle R/EHF.r :exports none :eval no
  ## calculate daily excess heat factor (ehf)
  ## arguments:
  ## ta: ideally of avg(tmax, tmin). Orig suggests same 0900-0900 period. No missings 
  ## t95: historical 95th percentile (optional, if missing this is computed). Orig suggests 1971-2000
  ## forward: the day aggregatopms are sampled either 1) as a
  ## foward-looking period (for the current day and following two days
  ## (i.e., days i, i+1 and i+2), or 2) the retrospective view (i.e., days
  ## i, i–1 and i–2). This is motivated by the intention to apply these
  ## ideas in the context of a weather forecasting service looking
  ## forward in time, but as Scalley points out a lag of at least three
  ## days from the threshold event to the peak health effect would be
  ## expected in the forward version.
  ## returns daily ehf series


  EHF <- function(ta, t95 = NULL, forward = F) {
  if(forward)
      t3 <- zoo::rollapply(ta, width = 3, FUN = mean, fill = NA, align = "left")
      t30 <- zoo::rollapplyr(
                      c(rep(NA, 1),ta[1:(length(ta)-1)])
                    , width = 30, FUN = mean, fill = NA)

  } else {
      t3 <- zoo::rollapplyr(ta, width = 3, FUN = mean, fill = NA)
      t30 <- zoo::rollapplyr(
                    c(rep(NA, 3), ta[1:(length(ta)-3)])
                    , width = 30, FUN = mean, fill = NA)
      
  }   
  # calculate the 95th centile?
  if(is.null(t95)){
     t95 <- quantile(ta, 0.95, na.rm = T)
  }
  # now calculate the EHI
  EHIsig <- t3 - t95
  EHIaccl <- t3 - t30
  EHF <- EHIsig * pmax(1, EHIaccl)
  return(EHF)
  }

#+end_src
*** QC backward
>     head(data.frame(lag = 32-0:(length(ta)-1), ta =ta,  tal=c(rep(NA, 3), ta[1:(length(ta)-3)]),t3=t3, t30= t30), 34)
   lag     ta    tal       t3      t30
1   32 23.635     NA       NA       NA
2   31 24.940     NA       NA       NA
3   30 26.160     NA 24.91167       NA
4   29 27.160 23.635 26.08667       NA
5   28 26.910 24.940 26.74333       NA
6   27 26.450 26.160 26.84000       NA
7   26 26.940 27.160 26.76667       NA
8   25 27.320 26.910 26.90333       NA
9   24 31.990 26.450 28.75000       NA
10  23 32.620 26.940 30.64333       NA
11  22 29.525 27.320 31.37833       NA
12  21 32.555 31.990 31.56667       NA
13  20 30.310 32.620 30.79667       NA
14  19 30.235 29.525 31.03333       NA
15  18 33.540 32.555 31.36167       NA
16  17 33.455 30.310 32.41000       NA
17  16 35.390 30.235 34.12833       NA
18  15 36.130 33.540 34.99167       NA
19  14 34.900 33.455 35.47333       NA
20  13 32.870 35.390 34.63333       NA
21  12 30.880 36.130 32.88333       NA
22  11 29.390 34.900 31.04667       NA
23  10 29.505 32.870 29.92500       NA
24   9 32.885 30.880 30.59333       NA
25   8 32.145 29.390 31.51167       NA
26   7 26.140 29.505 30.39000       NA
27   6 19.655 32.885 25.98000       NA
28   5 21.985 32.145 22.59333       NA
29   4 22.920 26.140 21.52000       NA
30   3 23.370 19.655 22.75833       NA
31   2 24.660 21.985 23.65000       NA
32   1 27.385 22.920 25.13833       NA
33   0 32.135 23.370 28.06000 29.06367
34  -1 33.550 24.660 31.02333 29.09783
> mean(ta[1:30])
[1] 29.06367
> mean(ta[31:33])
[1] 28.06
> 
*** QC forward

#+begin_src R :session *R* :tangle no :exports none :eval no
  'name:no'
  head(data.frame(lag = 32-0:(length(ta)-1), ta =ta,
                  tal=c(rep(NA, 1), ta[1:(length(ta)-1)]),
                  t3=t3, t30= t30), 35)
     lag     ta    tal       t3      t30
  1   32 23.635     NA 24.91167       NA
  2   31 24.940 23.635 26.08667       NA
  3   30 26.160 24.940 26.74333       NA
  4   29 27.160 26.160 26.84000       NA
  5   28 26.910 27.160 26.76667       NA
  6   27 26.450 26.910 26.90333       NA
  7   26 26.940 26.450 28.75000       NA
  8   25 27.320 26.940 30.64333       NA
  9   24 31.990 27.320 31.37833       NA
  10  23 32.620 31.990 31.56667       NA
  11  22 29.525 32.620 30.79667       NA
  12  21 32.555 29.525 31.03333       NA
  13  20 30.310 32.555 31.36167       NA
  14  19 30.235 30.310 32.41000       NA
  15  18 33.540 30.235 34.12833       NA
  16  17 33.455 33.540 34.99167       NA
  17  16 35.390 33.455 35.47333       NA
  18  15 36.130 35.390 34.63333       NA
  19  14 34.900 36.130 32.88333       NA
  20  13 32.870 34.900 31.04667       NA
  21  12 30.880 32.870 29.92500       NA
  22  11 29.390 30.880 30.59333       NA
  23  10 29.505 29.390 31.51167       NA
  24   9 32.885 29.505 30.39000       NA
  25   8 32.145 32.885 25.98000       NA
  26   7 26.140 32.145 22.59333       NA
  27   6 19.655 26.140 21.52000       NA
  28   5 21.985 19.655 22.75833       NA
  29   4 22.920 21.985 23.65000       NA
  30   3 23.370 22.920 25.13833       NA
  31   2 24.660 23.370 28.06000 29.06367
  32   1 27.385 24.660 31.02333 29.09783
  33   0 32.135 27.385 31.44833 29.17933
  34  -1 33.550 32.135 31.25500 29.37850
  35  -2 28.660 33.550 30.85167 29.59150
  > length(ta[3:32])
  [1] 30
  > mean(ta[3:32])
  [1] 29.17933
  > mean(ta[33:35])
  [1] 31.44833
  > 
#+end_src

*** COMMENT EHF_integration
#+name:EHF_integration
#+begin_src R :session *R* :tangle R/EHF_integration.R :exports none :eval no
EHF_integration <- function(EHF){

    index <- 1:length(ehf)
    analyte <- data.frame(index, EHF)

    analyte <- na.omit(analyte)  
    # proposed integrations
    # counts can be done quicker with this
    x <- analyte$EHF >= 0
    xx <- (cumsum(!x) + 1) * x 
    x2<-(seq_along(x) - match(xx, xx) + 1) * x 
    analyte$EHFcount <- x2

    # alternately, slower but more interpretable
    # analyte$EHIacclCount2<-as.numeric(0)
    # # 
    # which(analyte$dates == as.Date('2009-1-1'))
    # which(analyte$dates == as.Date('2009-3-1'))
    
    # for(j in 43034:43093){
    # # j=43034
    # analyte$EHIacclCount2[j] <- ifelse(analyte$EHIaccl[j] < 0, 0,
    # ifelse(analyte$EHIaccl[j-1] >= 0, 1 + analyte$EHIacclCount2[j-1],
    # 1)
    # )
    # }
      
    # sums
    EHFinverted  <- analyte$EHF * -1 
    y <- ifelse(EHFinverted >= 0, 0, analyte$EHF)
    f <- EHFinverted < 0
    f <- (cumsum(!f) + 1) * f

      
    z <- unsplit(lapply(split(y,f),cumsum),f)
    analyte$EHFintegrated <- z
    
    # alternately, slower but more interpretable
    # analyte$EHFintegrated2 <- as.numeric(0)
    # for(j in 43034:43093){
    # # j = 43034
          # analyte$EHFintegrated2[j] <- ifelse(analyte$EHF[j] < 0,0,
           # ifelse(analyte$EHF[j-1] >= 0,
           # analyte$EHF[j] + analyte$EHFintegrated2[j-1],
           # analyte$EHF[j])
           # )
          # }
                                          #head(analyte[680:nrow(analyte),], 50)
  #    str(id)
      id <- as.data.frame(index)
  #    str(analyte)
    analyte <- merge(id, analyte, all.x = T, by = "index")
  #  head(analyte, 50)  
    return(analyte)

      

   }


#+end_src

*** R deprecated
#+begin_src R :session *R* :tangle no :exports none :eval no
###############################################################################
 if (!require(Hmisc)) install.packages('Hmisc', repos='http://cran.csiro.au'); require(Hmisc)
 EHF <- function(analyte = data_subset,
  exposurename = 'air_temperature_in_degrees_c_max_climatezone_av',
  datename = 'date',
  referencePeriodStart = as.Date('1971-1-1'),
  referencePeriodEnd = as.Date('2000-12-31'),
  nlags = 32) {
  # TASK SHOULD WE IMPUTE MISSING DAYS?
 
  # first get lags
  # TASK THERE IS PROBABLY A VECTORISED VERSION THAT IS QUICKER?
  # TASK it is rollmean from the zoo package
  # ALTHOUGH THAT DOESNT HANDLE NAs SO TRY ROLLAPPLY?
  analyte$temp_lag0 <- analyte[,exposurename]
  exposuresList <- 'temp_lag0'
  # make sure in order
  analyte <- arrange(analyte,  analyte[,datename])
  # lag0 is not needed
  for(lagi in 1:nlags){
 	# lagi <- 1
 	exposuresList <- c(exposuresList, gsub('lag0',paste('lag', lagi,sep=''), exposuresList[1]))
 	analyte[,(ncol(analyte)+1)] <- Lag(analyte[,exposuresList[1]],lagi)
 	}
  exposuresList <- exposuresList[-1]
  names(analyte) <- c(names(analyte[,1:(ncol(analyte)-nlags)]),exposuresList)
  # head(analyte)
  # now 3 day av
  analyte$temp_movav <- rowMeans(analyte[,c('temp_lag0','temp_lag1','temp_lag2')], na.rm =FALSE)

  # now 30 day av
  # paste('temp_lag',3:32, sep = '', collapse = \"','\")
  analyte$temp30_movav <- rowMeans(analyte[,c('temp_lag3','temp_lag4','temp_lag5','temp_lag6','temp_lag7','temp_lag8','temp_lag9','temp_lag10','temp_lag11','temp_lag12','temp_lag13','temp_lag14','temp_lag15','temp_lag16','temp_lag17','temp_lag18','temp_lag19','temp_lag20','temp_lag21','temp_lag22','temp_lag23','temp_lag24','temp_lag25','temp_lag26','temp_lag27','temp_lag28','temp_lag29','temp_lag30','temp_lag31','temp_lag32')], na.rm =FALSE)
  # TASK note that this removes any missing days which could be imputed
  analyte <- na.omit(analyte)
  # head(analyte)
 
  # now calculate the EHI
  analyte$EHIaccl <- analyte$temp_movav - analyte$temp30_movav
  
  # first calculate the 95th centile
  referencestart <- referencePeriodStart
  referenceend <- referencePeriodEnd
  analyte$dateidCol <- analyte[,datename]
  reference <- subset(analyte, dateidCol >= referencestart & dateidCol <= referenceend, select = c('dateidCol', exposurename))
  head(reference);tail(reference)
  T95 <- quantile(reference[,exposurename], 0.95, na.rm = T)
  T95
 
  # now calculate the EHIsig
  analyte$EHIsig <- analyte$temp_movav - T95
  
  # now calculate the EHF
  analyte$EHF <- abs(analyte$EHIaccl) * analyte$EHIsig
  
  # proposed integrations
  # counts can be done quicker with this
  x <- analyte$EHIaccl >= 0
  xx <- (cumsum(!x) + 1) * x 
  x2<-(seq_along(x) - match(xx, xx) + 1) * x 
  analyte$EHIacclCount <- x2

  # alternately, slower but more interpretable
  # analyte$EHIacclCount2<-as.numeric(0)
  # # 
  # which(analyte$dates == as.Date('2009-1-1'))
  # which(analyte$dates == as.Date('2009-3-1'))
  
  # for(j in 43034:43093){
  # # j=43034
  # analyte$EHIacclCount2[j] <- ifelse(analyte$EHIaccl[j] < 0, 0,
  # ifelse(analyte$EHIaccl[j-1] >= 0, 1 + analyte$EHIacclCount2[j-1],
  # 1)
  # )
  # }
  
  x <- analyte$EHIsig >= 0
  xx <- (cumsum(!x) + 1) * x 
  x2<-(seq_along(x) - match(xx, xx) + 1) * x 
  analyte$EHIsigCount <- x2
  
  # sums
  EHFinverted  <- analyte$EHF * -1 
  y <- ifelse(EHFinverted >= 0, 0, analyte$EHF)
  f <- EHFinverted < 0
  f <- (cumsum(!f) + 1) * f 
  z <- unsplit(lapply(split(y,f),cumsum),f)
  analyte$EHFintegrated <- z
  
  # alternately, slower but more interpretable
  # analyte$EHFintegrated2 <- as.numeric(0)
  # for(j in 43034:43093){
  # # j = 43034
	# analyte$EHFintegrated2[j] <- ifelse(analyte$EHF[j] < 0,0,
	 # ifelse(analyte$EHF[j-1] >= 0,
	 # analyte$EHF[j] + analyte$EHFintegrated2[j-1],
	 # analyte$EHF[j])
	 # )
	# }
  
  return(analyte)
  }
 

#+end_src

*** Goldie version
#+begin_src R :session *R* :tangle R/EHF_goldie.R :exports none :eval no
# calculate daily excess heat factor (ehf)
# arguments:
#	tx: tmax time series
#	tn: tmin time series
#	t95: historical 95th percentile (ideally of avg(tx, tn) 0900-0900 1971-2000)
# returns daily ehf series

ehf_g <- function(tx, tn, t95)
{
	message('Calculating ehf')
    
	# use filter() to quickly calculate the moving averages required
	t3 = rowMeans(cbind(
		filter(tx, c(rep(1/3, 3), rep(0, 2)), method = 'convolution', sides = 2, circular = FALSE),
		filter(tn, c(rep(1/3, 3), rep(0, 4)), method = 'convolution', sides = 2, circular = FALSE)),
		na.rm = TRUE)
	t30 = rowMeans(cbind(
		filter(tx, c(rep(0, 31), rep(1/30, 30)), method = 'convolution', sides = 2, circular = FALSE),
		filter(tn, c(rep(0, 29), rep(1/30, 30)), method = 'convolution', sides = 2, circular = FALSE)),
		na.rm = TRUE)
	
	# bring it all together and return ehf
	ehi.sig = t3 - t95
	ehi.accl = t3 - t30
	ehf = ehi.sig * pmax(1, ehi.accl)

  message('Filling in missing ehf values')
    
  # which values are missing? (except for the edges that can't be done)
  missing.vals = which(is.na(ehf))
  missing.vals =
  missing.vals[! missing.vals %in% c(1:30, (length(tx) - 2):length(tx))]
    
	# fill in missing data manually
	for (i in missing.vals)
	{
		# get rolling tx, tn windows
		t3x = tx[i:(i + 2)]
		t3n = tn[(i + 1):(i + 3)]
		t30x = tx[(i - 30):(i - 1)]
		t30n = tn[(i - 29):i]

		# calc ehf if there's enough data
		if (length(which(is.na(t3x))) <= 1 ||
				length(which(is.na(t3n))) <= 1 ||
				length(which(is.na(t30x))) <= 5 ||
				length(which(is.na(t30n))) <= 5)
		{
				t3 = mean(c(
						mean(t3x, na.rm = TRUE),
						mean(t3n, na.rm = TRUE)))
				t30 = mean(c(
						mean(t30x, na.rm = TRUE),
						mean(t30n, na.rm = TRUE)))
				ehf[i] = (t3 - t95) * pmax(1, t3 - t30)
		}
	}
	return(ehf)
}

# threedmt: lowest maximum of today and the next two days
threedmt <- function(tx)
{
	message('Calculating threedmt')

	# quick version with rollapply
	threedmt = rollapply(tx, width = 3, FUN = min, fill = NA, align = 'left')

	message('Filling in missing 3dmt values')

	# which values are missing? (except for the edges that can't be done)
	missing.vals = which(is.na(threedmt))
	missing.vals =
		missing.vals[! missing.vals %in% (length(tx) - 1):length(tx)]

	# fill missing data in manually
	for (i in missing.vals)
	{
		# get rolling tx window
		txi = tx[i:(i + 2)]

		# calc 3dmt if there's enough data
		if (length(which(is.na(txi))) <= 1)
			threedmt[i] = min(txi, na.rm = TRUE)
	}
	return(threedmt)
}

# today's dat is the mean of tx today and tn tomorrow.
# threedat is the mean of dat for today + next two days
threedat <- function(tx, tn)
{
	message('Calculating threedat')
	# do the initial work quickly with filter()
	threedat =
		rowMeans(cbind(
			filter(tx, c(rep(1/3, 3), rep(0, 2)), method = 'convolution', sides = 2, circular = FALSE),
			filter(tn, c(rep(1/3, 3), rep(0, 4)), method = 'convolution', sides = 2, circular = FALSE)),
			na.rm = TRUE)

	message(run.time(), city, ': filling in missing 3dat values')

	# which values are missing? (except for the edges that can't be done)
	missing.vals = which(is.na(threedat))
	missing.vals =
			missing.vals[! missing.vals %in% (length(tx) - 2):length(tx)]

	# fill missing data in manually
	for (i in missing.vals)
	{
		# get rolling tx, tn windows 
		txi = tx[i:(i + 2)]
		tni = tn[(i + 1):(i + 3)]

		# cal if there's enough data
		if (length(which(is.na(txi))) <= 1 &&
				length(which(is.na(tni))) <= 1)
				threedat[i] = mean(c(
						mean(txi, na.rm = TRUE),
						mean(tni, na.rm = TRUE)),
						na.rm = TRUE)
	}
	return(threedat)
}

# returns a vector lagged by n elements (last n elements are lost)
# use a negative n to bring the series forward (now commented out)
# nb: dplyr::lag is equivalent and a little more defensive
lag <- function(x, n)
{
	if (n == 0) 
	{
		return(x)
	} else if (n > 0)
	{
		return(c(rep(NA, n), x[1:(length(x) - n)]))
	} else if (n < 0)
	{
		stop('Error in lag: must provide n >= 0')
	}

}

#+end_src

*** man
#+name:EHF
#+begin_src markdown :tangle man/EHF.Rd :exports none :eval no
\name{EHF}
\alias{EHF}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{
Excess Heat Factor
}
\description{
The EHF is an extension to a high pass filter, compared with long term percentiles.
}
\usage{
EHF(analyte = data_subset, exposurename = "air_temperature_in_degrees_c_max_climatezone_av", datename = "date", referencePeriodStart = as.Date("1971-1-1"), referencePeriodEnd = as.Date("2000-12-31"), nlags = 32)
}
%- maybe also 'usage' for other objects documented here.
\arguments{
  \item{analyte}{
dataframe
}
  \item{exposurename}{
the name of the exposure variable in the dataframe
}
  \item{datename}{
usually just date
}
  \item{referencePeriodStart}{
start of baseline climate reference period
}
  \item{referencePeriodEnd}{
end of baseline
}
  \item{nlags}{
number of lags, default is 32
}
}
\details{

}
\value{
A dataframe.
}
\references{
%% ~put references to the literature/web site here ~
}
\author{
ivanhanigan, original by John Nairn (Australian Bureau of Meteorology)
}
\note{
%%  ~~further notes~~
}



\seealso{
%% ~~objects to See Also as \code{\link{help}}, ~~~
}
\examples{

output <- EHF(analyte = data_subset, exposurename = "air_temperature_in_degrees_c_max_climatezone_av", 
    datename = "date", referencePeriodStart = as.Date("1971-1-1"), 
    referencePeriodEnd = as.Date("2000-12-31"), nlags = 32) 

}
% Add one or more standard keywords, see file 'KEYWORDS' in the
% R documentation directory.
\keyword{ ~kwd1 }
\keyword{ ~kwd2 }% __ONLY ONE__ keyword per line

#+end_src
** tapparent
#+name:tapparent
#+begin_src R :session *R* :tangle R/tapparent.R :exports none :eval no

  # steadman 1994 (and BoM Ta + 0.33×e − 0.70×ws − 4.00)
  tapparent <- function(ta, vprph, ws = 0){

    tapparent <- ta + (0.33 * vprph) - (0.70 * ws) - 4.00

    return(tapparent)
  }

#+end_src
** wbgt_guillaume

#+begin_src R :session *R* :tangle R/wbgt_guillaume.R :exports none :eval no
"
Various functions to calculate WBGT
Translated to R from Bruno Lemke's wbgt_calcs.xls vba by Joseph Guillaume, January 2008
Needed to be made vector-input safe, i.e. all operations in functions must be element-wise
 or function must deal with vector input as scalars separately

Ta - air temperature degC
dewpoint degC
windspeed m/s
solarrad - solar radiation W/m^2
pressure mB

!     This product includes software produced by UChicago Argonne, LLC 
!     under Contract No. DE-AC02-06CH11357 with the Department of Energy.


!                Copyright © 2008, UChicago Argonne, LLC
!                        All Rights Reserved
!
!                         WBGT, Version 1.0
!
!                        James C. Liljegren
!               Decision & Information Sciences Division
!
!                        OPEN SOURCE LICENSE
!
!  Redistribution and use in source and binary forms, with or without modification, 
!  are permitted provided that the following conditions are met:
!
!  1. Redistributions of source code must retain the above copyright notice, 
!     this list of conditions and the following disclaimer.  Software changes, 
!     modifications, or derivative works, should be noted with comments and 
!     the author and organization’s name.
!
!  2. Redistributions in binary form must reproduce the above copyright notice, 
!     this list of conditions and the following disclaimer in the documentation 
!     and/or other materials provided with the distribution.
!
!  3. Neither the names of UChicago Argonne, LLC or the Department of Energy 
!     nor the names of its contributors may be used to endorse or promote products 
!     derived from this software without specific prior written permission.
!
!  4. The software and the end-user documentation included with the 
!     redistribution, if any, must include the following acknowledgment:
!
!     This product includes software produced by UChicago Argonne, LLC 
!     under Contract No. DE-AC02-06CH11357 with the Department of Energy.”
!
!******************************************************************************************
!  DISCLAIMER
!
!  THE SOFTWARE IS SUPPLIED AS IS WITHOUT WARRANTY OF ANY KIND.
!
!  NEITHER THE UNITED STATES GOVERNMENT, NOR THE UNITED STATES DEPARTMENT OF ENERGY, 
!  NOR UCHICAGO ARGONNE, LLC, NOR ANY OF THEIR EMPLOYEES, MAKES ANY WARRANTY, EXPRESS 
!  OR IMPLIED, OR ASSUMES ANY LEGAL LIABILITY OR RESPONSIBILITY FOR THE ACCURACY, 
!  COMPLETENESS, OR USEFULNESS OF ANY INFORMATION, DATA, APPARATUS, PRODUCT, OR 
!  PROCESS DISCLOSED, OR REPRESENTS THAT ITS USE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS.
!
!******************************************************************************************

	program wbgt
!
!  Purpose: to demonstrate the use of the subroutine calc_wbgt to calculate
!           the wet bulb-globe temperature (WBGT).  The program reads input 
!           data from a file containing meteorological measurements then 
!           calls calc_wbgt to compute the WBGT.
!
!           The inputs and outputs are fully described in calc_wbgt.
!
!  Author:  James C. Liljegren
!		Decision and Information Sciences Division
!		Argonne National Laboratory
!		
"

esat<-function(tk){
#  Purpose: calculate the saturation vapor pressure (mb) over liquid water given the temperature (K).
#
#  Reference: Buck's (1981) approximation (eqn 3) of Wexler's (1976) formulae.
#  over liquid water

	y = (tk - 273.15) / (tk - 32.18)
	es = 6.1121 * exp(17.502 * y)
	es = 1.004 * es  # correction for moist air, if pressure is not available; for pressure > 800 mb

	esat = es
	return(esat)
}

emis_atm<-function(t, rh){
#
#  Reference: Oke (2nd edition), page 373.
#
	e = rh * esat(t)
	emis_atm = 0.575 * e ^ 0.143
	return(emis_atm)
}

thermal_cond<-function(Tair){
#
#  Purpose: Compute the thermal conductivity of air, W/(m K) given temperature, K
#
#  Reference: BSL, page 257.
	Cp = 1003.5
	Rair = 8314.34 / 28.97

	thermal_cond = (Cp + 1.25 * Rair) * viscosity(Tair)
	return(thermal_cond)
}

viscosity<-function(Tair){
#
#  Purpose: Compute the viscosity of air, kg/(m s) given temperature, K
#
#  Reference: BSL, page 23.
#
	sigma = 3.617
	sigma2 = sigma ^ 2
	epsKappa = 97
	Mair = 28.97
	Tr = Tair / epsKappa
	omega = (Tr - 2.9) / 0.4 * (-0.034) + 1.048
	viscosity = 0.0000026693 * (Mair * Tair) ^ 0.5 / (sigma2 * omega)
	return(viscosity)
}


h_sphere_in_air<-function(Tair, Pair, speed, speedMin){
#
#  Purpose: to calculate the convective heat tranfer coefficient for flow around a sphere.
#
#  Reference: Bird, Stewart, and Lightfoot (BSL), page 409.
	Rair = 8314.34 / 28.97
	Pr = 1003.5 / (1003.5 + 1.25 * Rair)
	diameter = 0.15

	density = Pair * 100 / (Rair * Tair)   # kg/m3
      if(speed < speedMin) speed = speedMin
      Re = speed * density * diameter / viscosity(Tair)
	Nu = 2 + 0.6 * Re ^ 0.5 * Pr ^ 0.3333
	h_sphere_in_air = Nu * thermal_cond(Tair) / diameter # W/(m2 K)
	return(h_sphere_in_air)
}

#Modified to accept vector input & NA values. Joseph Guillaume 20080130
fTg<-function(Ta, relh, Pair, speed, solar, fdir, speedMin){
	if (length(Ta)>1) {
		if (length(fdir)==1) fdir<-rep(fdir,length(Ta))
		if (length(speedMin)==1) speedMin<-rep(speedMin,length(Ta))

		res<-rep(NA,length(Ta))
		for (i in 1:length(Ta)) res[i]<-fTg(Ta[i], relh[i], Pair[i], speed[i], solar[i], fdir[i], speedMin[i])
		return(res)
	} else {
	if (any(is.na(c(Ta,relh,Pair,speed,solar,fdir,speedMin)))) return(NA)

#
#  Purpose: to calculate the globe Ta
#  Author:  James C. Liljegren
#       Decision and Information Sciences Division
#       Argonne National Laboratory
#
# Pressure in millibar (Atm =1010 mB)
#    Direct radiation so cosZ=1
	cza = 1
	converge = 0.02
	alb_sfc = 0.45
	alb_globe = 0.05
	stefanb = 0.000000056696
	emis_globe = 0.95
	emis_sfc = 0.999
	Tair = Ta + 273.15
 	rh = relh * 0.01
	Tsfc = Tair
	Tglobe_prev = Tair
	while (TRUE){
		Tref = 0.5 * (Tglobe_prev + Tair) # Evaluate properties at the average temperature
		h = h_sphere_in_air(Tref, Pair, speed, speedMin)
		Tglobe = (0.5 * (emis_atm(Tair, rh) * Tair ^ 4 + emis_sfc * Tsfc ^ 4) - h / (emis_globe * stefanb) * (Tglobe_prev - Tair) + solar / (2 * emis_globe * stefanb) * (1 - alb_globe) * (fdir * (1 / (2 * cza) - 1) + 1 + alb_sfc)) ^ 0.25
		dT = Tglobe - Tglobe_prev
		if (abs(dT) < converge) {
			Tglobe = Tglobe - 273.15
			break
		} else {
			Tglobe_prev = (0.9 * Tglobe_prev + 0.1 * Tglobe)
		}
	}
    return(Tglobe)
}}

#Modified to accept vector input. Joseph Guillaume. 20090130
fTw<-function(Ta,Td){
	if (length(Ta)!=length(Td)) stop("Need same number of Ta and Td measurements")
	if (length(Ta)>1) {
		res<-rep(NA,length(Ta))
		for (i in 1:length(Ta)) res[i]<-fTw(Ta[i],Td[i])
		return(res)
	} else {
	if (Ta==0 || Td==0 || is.na(Ta) || is.na(Td)) return(NA)

	Tw = Td
	Diff = 10000
	Ed = 0.6106 * exp(17.27 * Td / (237.3 + Td))

	Diffold = Diff
	while (abs(Diff) + abs(Diffold) == abs(Diff + Diffold)){
		Diffold = Diff
		Ew = 0.6106 * exp(17.27 * Tw / (237.3 + Tw))
		Diff = 1556 * Ed + 101 * Ta - 1556 * Ew + 1.484 * Ew * Tw - 1.484 * Ed * Tw - 101 * Tw
		Tw = Tw + 0.2
		if (Tw > Ta) break
	}
	if (Tw > Td + 0.3) fTw = Tw - 0.3
	else fTw = Td
	return(fTw)
	}
}

calc_relhum<-function(Ta,dewpoint) return(100*exp(17.27*dewpoint/(237.7+dewpoint)-17.27*Ta/(237.7+Ta)))

#Either Tw or dewpoint must be provided
#If Tw is not provided, it is calculated using dewpoint
calc_Tnwb_bernard<-function(Tg,Ta,windspeed,Tw=NA,dewpoint=NA){
	if (length(Ta)>1) {
		res<-rep(NA,length(Ta))
		for (i in 1:length(Ta)) res[i]<-calc_Tnwb_bernard(Tg[i],Ta[i],windspeed[i],Tw[i],dewpoint[i])
		return(res)
	} else {
	if (any(is.na(c(Ta,Tg,windspeed)))) return(NA)

	if (is.na(Tw) && !is.na(dewpoint)) Tw=fTw(Ta,dewpoint)
	if(Tg-Ta>4) return(X(Ta,windspeed,Tw,Tg))
	else {
		if(windspeed>3) return(Tw)
		else return(Ta-(0.069*log10(windspeed+0.1)+0.96)*(Ta-Tw))
	}
}}

calc_wbgt_bom<-function(Ta,relhum=NA,e=NA){
	if (is.na(e) && !is.na(relhum)) e<-relhum/100*6.105*exp(17.27*Ta/(237.7+Ta))
	return(0.567 *Ta+0.393*e+3.94)
}

calc_wbgt_indoors_tw<-function(Tw,Ta) return(0.7*Tw+0.3*Ta+0.55) #using Tw
calc_wbgt_outdoors_tonouchi<-function(Tw,Ta,solarrad,windspeed) return(0.7*Tw + 0.3*Ta + 0.0117*solarrad - 0.205*windspeed + 0.751)

#Either Tnwb or windspeed must be provided
#if Tnwb is not provided, it is calculated using the Bernard formula
calc_wbgt_outdoors_liljegren_bernard<-function(Ta,Tg,Tnwb=NA,windspeed=NA) {
	if (is.na(Tnwb) && !is.na(windspeed)) Tnwb<-calc_Tnwb_bernard(Tg,Ta,windspeed)
	return(0.7*Tnwb+0.1*Ta+0.2*Tg)
}

X<-function(Ta,windspeed,Tw,Tg){
	if (length(Ta)>1) {
		res<-rep(NA,length(Ta))
		for (i in 1:length(Ta)) res[i]<-X(Ta[i],windspeed[i],Tw[i],Tg[i])
		return(res)
	} else {

	if(Tg-Ta>4 && windspeed>1) {
		return(Tw+0.25*(Tg-Ta)-0.1)
	} else if(Tg-Ta>4) {
		return(Tw+0.25*(Tg-Ta)+0.1/(windspeed+0.1)^1.1-0.2)
	} else { return(NA) }
}}

get_wbgt_values<-function(Ta,dewpoint,windspeed=1,solarrad=980,pressure=1001,full_excel_line=FALSE){
	Tw<-fTw(Ta,dewpoint)

	#Needs Ta,dewpoint
	wbgt_indoors_tw<-calc_wbgt_indoors_tw(Tw,Ta)

	#Needs Ta,dewpoint,solarrad,windspeed
	wbgt_outdoors_tonouchi<-calc_wbgt_outdoors_tonouchi(Tw,Ta,solarrad,windspeed)

	relhum<-calc_relhum(Ta,dewpoint)
	Tg<-fTg(Ta,relhum, pressure, windspeed, solarrad, 0.6,1)

	Tnwb<-calc_Tnwb_bernard(Tg,Ta,windspeed,Tw=Tw)
	#Needs Ta,relhum,pressure,windspeed,solarrad,dewpoint
	wbgt_outdoors_liljegren_bernard<-calc_wbgt_outdoors_liljegren_bernard(Ta,Tg,Tnwb)

	#Needs Ta, windspeed, Tw, Tg (TODO X is causing failure)
	#x=X(Ta,windspeed,Tw,Tg)

	if (full_excel_line){
	return(data.frame(
		Ta=Ta,
		dewpoint=dewpoint,
		windspeed=windspeed,
		solarrad=solarrad,
		pressure=pressure,
		relhum=relhum,
		Tw=Tw,
		Tnwb=Tnwb,
		Tg=Tg,
		wbgt_indoors_tw=wbgt_indoors_tw,
		wbgt_outdoors_tonouchi=wbgt_outdoors_tonouchi,
		wbgt_outdoors_liljegren_bernard=wbgt_outdoors_liljegren_bernard,
		X=x
	)) } else {
	return(data.frame(
		wbgt_indoors_tw=wbgt_indoors_tw,
		wbgt_outdoors_tonouchi=wbgt_outdoors_tonouchi,
		wbgt_outdoors_liljegren_bernard=wbgt_outdoors_liljegren_bernard
	)) }
}

#TESTING AGAINST ORIGINAL SPREADSHEET
if (FALSE){

#ans is columns E:Q from original spreadsheet (E:I are inputs,J:Q are calculated)
err_line<-function (ans){
	return(get_wbgt_values(ans[1],ans[2],ans[3],ans[4],ans[5],full_excel_line=TRUE)-ans)
}
e<-err_line(c(36,11,1,980,1001,22.14217223,20.1,27.49324803,66.01280514,25.42,36.882,36.04783465,27.49324803))
print(all(na.omit(e<1e-6)))
e<-err_line(c(25,20,30,300,1001,73.84576627,21.5,21.5,27.62714571,23.1,20.661,23.07542914,NA))
print(all(na.omit(e<1e-6)))
e<-err_line(c(26,15,15,1100,980,50.78141797,18.9,22.3487882,40.19515282,21.58,31.576,26.28318231,22.3487882))
print(all(na.omit(e<1e-6)))
e<-err_line(c(16,19,10,930,1200,120.8164345,19,22.24305356,29.37221424,18.65,27.682,23.04458034,22.24305356))
print(all(na.omit(e<1e-6)))

#Test for same input in vector form
#ans is data frame
err_matrix<-function(ans){
	return(get_wbgt_values(ans[,1],ans[,2],ans[,3],ans[,4],ans[,5],full_excel_line=TRUE)-ans)
}
ans<-data.frame()
ans<-rbind(ans,c(36,11,1,980,1001,22.14217223,20.1,27.49324803,66.01280514,25.42,36.882,36.04783465,27.49324803))
ans<-rbind(ans,c(25,20,30,300,1001,73.84576627,21.5,21.5,27.62714571,23.1,20.661,23.07542914,NA))
ans<-rbind(ans,c(26,15,15,1100,980,50.78141797,18.9,22.3487882,40.19515282,21.58,31.576,26.28318231,22.3487882))
ans<-rbind(ans,c(16,19,10,930,1200,120.8164345,19,22.24305356,29.37221424,18.65,27.682,23.04458034,22.24305356))

e<-err_matrix(ans)
print(all(na.omit(e<1e-6)))
}


#+end_src

** swbgt
*** notes
http://www.bom.gov.au/info/thermal_stress/#wbgt
cited 19/9/2017

Values for the black globe temperature and natural wet-bulb temperature cannot be accurately determined from a standard meteorological site.

Instead the Bureau uses an approximation to the WBGT. This approximation uses standard meteorologically measured temperature and humidity to calculate an estimation of the WBGT under moderately sunny light wind conditions. Real variations of sunshine and wind are not taken into account. The formula is likely to overestimate the WBGT in cloudy or windy conditions, or when the sun is low or below the horizon. Under clear full sun and low humidity conditions the approximation underestimates the WBGT slightly. The formula for the approximation is shown at the end of this document. 
*** code

#+begin_src R :session *R* :tangle R/swbgt.R :exports none :eval no
swbgt <- function(ta, vprph){
  swbgt <- (0.567 * ta) + (0.393 * vprph) + 3.94

  return(swbgt)
}
#+end_src
** dewpt
#+name:dewpt
#+begin_src R :session *R* :tangle R/dewpt.R :exports none :eval no
'name:dewpt'
# https://github.com/martinluther/meteo/blob/master/wunderground/meteo-wu-fmt.pl
# orig formulas from http://www.usatoday.com/weather/whumcalc.htm
#
# returns a dewpoint given a temp (celsius) and relative humidity
#
# Logic: First, obtain the saturation vapor pressure(Es) using formula (5)
# from air temperature Tc. 
#
# (5) Es=6.11*10.0**(7.5*Tc/(237.7+Tc)) 
#
# The next step is to use the saturation vapor pressure and the relative humidity
# to compute the actual vapor pressure(E) of the air. This can be done with
# the following formula. 
#
# (9) E=(RH*Es)/100 
#
# RH=relative humidity of air expressed as a percent.(i.e. 80%) 
#
# Now you are ready to use the following formula to obtain the
# dewpoint temperature. 
#
# Note: ln( ) means to take the natural log of the variable in the parentheses 
#
# (10) Tdc=(-430.22+237.7*ln(E))/(-ln(E)+19.08) 
#
dewpt <- function(Tc, RH){

  Es <- 6.11 * 10.0^(7.5 * Tc / (237.7 + Tc))
  E <- (RH * Es) / 100
  Tdc <- (-430.22 + 237.7 * log(E)) / (-log(E) +19.08)

  return(Tdc)
}    

#+end_src
